{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn Package on Dissertation Datasets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "#from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load iris data and put them in $X$ and $y$ variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[19  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0 15]]\n",
      "Accuracy \n",
      " 0.98\n"
     ]
    }
   ],
   "source": [
    "# choose a classifier with relevant parameters\n",
    "\n",
    "# KNN for example\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "model = clf.fit(X_train,y_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "\n",
    "conf = confusion_matrix(pred_test, y_test)\n",
    "score = accuracy_score(pred_test, y_test)\n",
    "print('Confusion Matrix \\n',conf)\n",
    "print('Accuracy \\n', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary-Class Problems\n",
    "---\n",
    "**Breast Cancer Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Logistic Regression***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data,cancer.target, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 63   4]\n",
      " [  4 117]]\n",
      "Accuracy: \n",
      " 0.96\n",
      "10-Fold Cross Validation accuracies are: \n",
      " [0.95 0.91 0.93 0.95 0.96 0.98 0.95 0.95 0.96 0.96]\n",
      "Cross Validated Accuracy: \n",
      " 0.95 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression for the cancer sklearn dataset\n",
    "clf = LogisticRegression()\n",
    "model = clf.fit(X_train,y_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "\n",
    "# 10-fold cross validation\n",
    "scores = cross_val_score(clf, cancer.data, cancer.target, cv=10)\n",
    "\n",
    "conf = confusion_matrix(pred_test, y_test)\n",
    "score = accuracy_score(pred_test, y_test)\n",
    "print('Confusion Matrix: \\n',conf)\n",
    "print('Accuracy: \\n', np.round(score,2))\n",
    "print('10-Fold Cross Validation accuracies are: \\n', np.round(scores,2))\n",
    "print('Cross Validated Accuracy: \\n %0.2f (+/- %0.2f)'% (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 62   3]\n",
      " [  5 118]]\n",
      "Accuracy: \n",
      " 0.96\n",
      "10-Fold Cross Validation accuracies are: \n",
      " [0.98 0.91 0.93 0.96 1.   0.98 0.96 0.98 0.95 1.  ]\n",
      "Cross Validated Accuracy: \n",
      " 0.97 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "\n",
    "conf = confusion_matrix(pred_test, y_test)\n",
    "score = accuracy_score(pred_test, y_test)\n",
    "print('Confusion Matrix: \\n',conf)\n",
    "print('Accuracy: \\n', np.round(score,2))\n",
    "\n",
    "\n",
    "# 10-fold cross validation\n",
    "scores = cross_val_score(clf, cancer.data, cancer.target, cv=10)\n",
    "print('10-Fold Cross Validation accuracies are: \\n', np.round(scores,2))\n",
    "print('Cross Validated Accuracy: \\n %0.2f (+/- %0.2f)'% (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nearest Neighbours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[ 62   6]\n",
      " [  5 115]]\n",
      "Accuracy \n",
      " 0.9414893617021277\n",
      "10-Fold Cross Validation accuracies are: \n",
      " [0.91 0.86 0.89 0.95 0.95 0.95 0.96 0.95 0.91 0.93]\n",
      "Cross Validated Accuracy: \n",
      " 0.93 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "model = clf.fit(X_train,y_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "\n",
    "conf = confusion_matrix(pred_test, y_test)\n",
    "score = accuracy_score(pred_test, y_test)\n",
    "print('Confusion Matrix \\n',conf)\n",
    "print('Accuracy \\n', score)\n",
    "\n",
    "# 10-fold cross validation\n",
    "scores = cross_val_score(clf, cancer.data, cancer.target, cv=10)\n",
    "print('10-Fold Cross Validation accuracies are: \\n', np.round(scores,2))\n",
    "print('Cross Validated Accuracy: \\n %0.2f (+/- %0.2f)'% (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[ 61   5]\n",
      " [  6 116]]\n",
      "Accuracy \n",
      " 0.9414893617021277\n",
      "10-Fold Cross Validation accuracies are: \n",
      " [0.95 0.88 0.89 0.93 0.95 0.98 0.93 0.96 0.95 0.96]\n",
      "Cross Validated Accuracy: \n",
      " 0.94 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "model = clf.fit(X_train,y_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "\n",
    "conf = confusion_matrix(pred_test, y_test)\n",
    "score = accuracy_score(pred_test, y_test)\n",
    "print('Confusion Matrix \\n',conf)\n",
    "print('Accuracy \\n', score)\n",
    "\n",
    "# 10-fold cross validation\n",
    "scores = cross_val_score(clf, cancer.data, cancer.target, cv=10)\n",
    "print('10-Fold Cross Validation accuracies are: \\n', np.round(scores,2))\n",
    "print('Cross Validated Accuracy: \\n %0.2f (+/- %0.2f)'% (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0      1       2       3        4        5         6         7   \\\n",
      "0    17.990  10.38  122.80  1001.0  0.11840  0.27760  0.300100  0.147100   \n",
      "1    20.570  17.77  132.90  1326.0  0.08474  0.07864  0.086900  0.070170   \n",
      "2    19.690  21.25  130.00  1203.0  0.10960  0.15990  0.197400  0.127900   \n",
      "3    11.420  20.38   77.58   386.1  0.14250  0.28390  0.241400  0.105200   \n",
      "4    20.290  14.34  135.10  1297.0  0.10030  0.13280  0.198000  0.104300   \n",
      "5    12.450  15.70   82.57   477.1  0.12780  0.17000  0.157800  0.080890   \n",
      "6    18.250  19.98  119.60  1040.0  0.09463  0.10900  0.112700  0.074000   \n",
      "7    13.710  20.83   90.20   577.9  0.11890  0.16450  0.093660  0.059850   \n",
      "8    13.000  21.82   87.50   519.8  0.12730  0.19320  0.185900  0.093530   \n",
      "9    12.460  24.04   83.97   475.9  0.11860  0.23960  0.227300  0.085430   \n",
      "10   16.020  23.24  102.70   797.8  0.08206  0.06669  0.032990  0.033230   \n",
      "11   15.780  17.89  103.60   781.0  0.09710  0.12920  0.099540  0.066060   \n",
      "12   19.170  24.80  132.40  1123.0  0.09740  0.24580  0.206500  0.111800   \n",
      "13   15.850  23.95  103.70   782.7  0.08401  0.10020  0.099380  0.053640   \n",
      "14   13.730  22.61   93.60   578.3  0.11310  0.22930  0.212800  0.080250   \n",
      "15   14.540  27.54   96.73   658.8  0.11390  0.15950  0.163900  0.073640   \n",
      "16   14.680  20.13   94.74   684.5  0.09867  0.07200  0.073950  0.052590   \n",
      "17   16.130  20.68  108.10   798.8  0.11700  0.20220  0.172200  0.102800   \n",
      "18   19.810  22.15  130.00  1260.0  0.09831  0.10270  0.147900  0.094980   \n",
      "19   13.540  14.36   87.46   566.3  0.09779  0.08129  0.066640  0.047810   \n",
      "20   13.080  15.71   85.63   520.0  0.10750  0.12700  0.045680  0.031100   \n",
      "21    9.504  12.44   60.34   273.9  0.10240  0.06492  0.029560  0.020760   \n",
      "22   15.340  14.26  102.50   704.4  0.10730  0.21350  0.207700  0.097560   \n",
      "23   21.160  23.04  137.20  1404.0  0.09428  0.10220  0.109700  0.086320   \n",
      "24   16.650  21.38  110.00   904.6  0.11210  0.14570  0.152500  0.091700   \n",
      "25   17.140  16.40  116.00   912.7  0.11860  0.22760  0.222900  0.140100   \n",
      "26   14.580  21.53   97.41   644.8  0.10540  0.18680  0.142500  0.087830   \n",
      "27   18.610  20.25  122.10  1094.0  0.09440  0.10660  0.149000  0.077310   \n",
      "28   15.300  25.27  102.40   732.4  0.10820  0.16970  0.168300  0.087510   \n",
      "29   17.570  15.05  115.00   955.1  0.09847  0.11570  0.098750  0.079530   \n",
      "..      ...    ...     ...     ...      ...      ...       ...       ...   \n",
      "539   7.691  25.44   48.34   170.4  0.08668  0.11990  0.092520  0.013640   \n",
      "540  11.540  14.44   74.65   402.9  0.09984  0.11200  0.067370  0.025940   \n",
      "541  14.470  24.99   95.81   656.4  0.08837  0.12300  0.100900  0.038900   \n",
      "542  14.740  25.42   94.70   668.6  0.08275  0.07214  0.041050  0.030270   \n",
      "543  13.210  28.06   84.88   538.4  0.08671  0.06877  0.029870  0.032750   \n",
      "544  13.870  20.70   89.77   584.8  0.09578  0.10180  0.036880  0.023690   \n",
      "545  13.620  23.23   87.19   573.2  0.09246  0.06747  0.029740  0.024430   \n",
      "546  10.320  16.35   65.31   324.9  0.09434  0.04994  0.010120  0.005495   \n",
      "547  10.260  16.58   65.85   320.8  0.08877  0.08066  0.043580  0.024380   \n",
      "548   9.683  19.34   61.05   285.7  0.08491  0.05030  0.023370  0.009615   \n",
      "549  10.820  24.21   68.89   361.6  0.08192  0.06602  0.015480  0.008160   \n",
      "550  10.860  21.48   68.51   360.5  0.07431  0.04227  0.000000  0.000000   \n",
      "551  11.130  22.44   71.49   378.4  0.09566  0.08194  0.048240  0.022570   \n",
      "552  12.770  29.43   81.35   507.9  0.08276  0.04234  0.019970  0.014990   \n",
      "553   9.333  21.94   59.01   264.0  0.09240  0.05605  0.039960  0.012820   \n",
      "554  12.880  28.92   82.50   514.3  0.08123  0.05824  0.061950  0.023430   \n",
      "555  10.290  27.61   65.67   321.4  0.09030  0.07658  0.059990  0.027380   \n",
      "556  10.160  19.59   64.73   311.7  0.10030  0.07504  0.005025  0.011160   \n",
      "557   9.423  27.88   59.26   271.3  0.08123  0.04971  0.000000  0.000000   \n",
      "558  14.590  22.68   96.39   657.1  0.08473  0.13300  0.102900  0.037360   \n",
      "559  11.510  23.93   74.52   403.5  0.09261  0.10210  0.111200  0.041050   \n",
      "560  14.050  27.15   91.38   600.4  0.09929  0.11260  0.044620  0.043040   \n",
      "561  11.200  29.37   70.67   386.0  0.07449  0.03558  0.000000  0.000000   \n",
      "562  15.220  30.62  103.40   716.9  0.10480  0.20870  0.255000  0.094290   \n",
      "563  20.920  25.09  143.00  1347.0  0.10990  0.22360  0.317400  0.147400   \n",
      "564  21.560  22.39  142.00  1479.0  0.11100  0.11590  0.243900  0.138900   \n",
      "565  20.130  28.25  131.20  1261.0  0.09780  0.10340  0.144000  0.097910   \n",
      "566  16.600  28.08  108.30   858.1  0.08455  0.10230  0.092510  0.053020   \n",
      "567  20.600  29.33  140.10  1265.0  0.11780  0.27700  0.351400  0.152000   \n",
      "568   7.760  24.54   47.92   181.0  0.05263  0.04362  0.000000  0.000000   \n",
      "\n",
      "         8        9    ...         20     21      22      23       24  \\\n",
      "0    0.2419  0.07871   ...     25.380  17.33  184.60  2019.0  0.16220   \n",
      "1    0.1812  0.05667   ...     24.990  23.41  158.80  1956.0  0.12380   \n",
      "2    0.2069  0.05999   ...     23.570  25.53  152.50  1709.0  0.14440   \n",
      "3    0.2597  0.09744   ...     14.910  26.50   98.87   567.7  0.20980   \n",
      "4    0.1809  0.05883   ...     22.540  16.67  152.20  1575.0  0.13740   \n",
      "5    0.2087  0.07613   ...     15.470  23.75  103.40   741.6  0.17910   \n",
      "6    0.1794  0.05742   ...     22.880  27.66  153.20  1606.0  0.14420   \n",
      "7    0.2196  0.07451   ...     17.060  28.14  110.60   897.0  0.16540   \n",
      "8    0.2350  0.07389   ...     15.490  30.73  106.20   739.3  0.17030   \n",
      "9    0.2030  0.08243   ...     15.090  40.68   97.65   711.4  0.18530   \n",
      "10   0.1528  0.05697   ...     19.190  33.88  123.80  1150.0  0.11810   \n",
      "11   0.1842  0.06082   ...     20.420  27.28  136.50  1299.0  0.13960   \n",
      "12   0.2397  0.07800   ...     20.960  29.94  151.70  1332.0  0.10370   \n",
      "13   0.1847  0.05338   ...     16.840  27.66  112.00   876.5  0.11310   \n",
      "14   0.2069  0.07682   ...     15.030  32.01  108.80   697.7  0.16510   \n",
      "15   0.2303  0.07077   ...     17.460  37.13  124.10   943.2  0.16780   \n",
      "16   0.1586  0.05922   ...     19.070  30.88  123.40  1138.0  0.14640   \n",
      "17   0.2164  0.07356   ...     20.960  31.48  136.80  1315.0  0.17890   \n",
      "18   0.1582  0.05395   ...     27.320  30.88  186.80  2398.0  0.15120   \n",
      "19   0.1885  0.05766   ...     15.110  19.26   99.70   711.2  0.14400   \n",
      "20   0.1967  0.06811   ...     14.500  20.49   96.09   630.5  0.13120   \n",
      "21   0.1815  0.06905   ...     10.230  15.66   65.13   314.9  0.13240   \n",
      "22   0.2521  0.07032   ...     18.070  19.08  125.10   980.9  0.13900   \n",
      "23   0.1769  0.05278   ...     29.170  35.59  188.00  2615.0  0.14010   \n",
      "24   0.1995  0.06330   ...     26.460  31.56  177.00  2215.0  0.18050   \n",
      "25   0.3040  0.07413   ...     22.250  21.40  152.40  1461.0  0.15450   \n",
      "26   0.2252  0.06924   ...     17.620  33.21  122.40   896.9  0.15250   \n",
      "27   0.1697  0.05699   ...     21.310  27.26  139.90  1403.0  0.13380   \n",
      "28   0.1926  0.06540   ...     20.270  36.71  149.30  1269.0  0.16410   \n",
      "29   0.1739  0.06149   ...     20.010  19.52  134.90  1227.0  0.12550   \n",
      "..      ...      ...   ...        ...    ...     ...     ...      ...   \n",
      "539  0.2037  0.07751   ...      8.678  31.89   54.49   223.6  0.15960   \n",
      "540  0.1818  0.06782   ...     12.260  19.68   78.78   457.8  0.13450   \n",
      "541  0.1872  0.06341   ...     16.220  31.73  113.50   808.9  0.13400   \n",
      "542  0.1840  0.05680   ...     16.510  32.29  107.40   826.4  0.10600   \n",
      "543  0.1628  0.05781   ...     14.370  37.17   92.48   629.6  0.10720   \n",
      "544  0.1620  0.06688   ...     15.050  24.75   99.17   688.6  0.12640   \n",
      "545  0.1664  0.05801   ...     15.350  29.09   97.58   729.8  0.12160   \n",
      "546  0.1885  0.06201   ...     11.250  21.77   71.12   384.9  0.12850   \n",
      "547  0.1669  0.06714   ...     10.830  22.04   71.08   357.4  0.14610   \n",
      "548  0.1580  0.06235   ...     10.930  25.59   69.10   364.2  0.11990   \n",
      "549  0.1976  0.06328   ...     13.030  31.45   83.90   505.6  0.12040   \n",
      "550  0.1661  0.05948   ...     11.660  24.77   74.08   412.3  0.10010   \n",
      "551  0.2030  0.06552   ...     12.020  28.26   77.80   436.6  0.10870   \n",
      "552  0.1539  0.05637   ...     13.870  36.00   88.10   594.7  0.12340   \n",
      "553  0.1692  0.06576   ...      9.845  25.05   62.86   295.8  0.11030   \n",
      "554  0.1566  0.05708   ...     13.890  35.74   88.84   595.7  0.12270   \n",
      "555  0.1593  0.06127   ...     10.840  34.91   69.57   357.6  0.13840   \n",
      "556  0.1791  0.06331   ...     10.650  22.88   67.88   347.3  0.12650   \n",
      "557  0.1742  0.06059   ...     10.490  34.24   66.50   330.6  0.10730   \n",
      "558  0.1454  0.06147   ...     15.480  27.27  105.90   733.5  0.10260   \n",
      "559  0.1388  0.06570   ...     12.480  37.16   82.28   474.2  0.12980   \n",
      "560  0.1537  0.06171   ...     15.300  33.17  100.20   706.7  0.12410   \n",
      "561  0.1060  0.05502   ...     11.920  38.30   75.19   439.6  0.09267   \n",
      "562  0.2128  0.07152   ...     17.520  42.79  128.70   915.0  0.14170   \n",
      "563  0.2149  0.06879   ...     24.290  29.41  179.10  1819.0  0.14070   \n",
      "564  0.1726  0.05623   ...     25.450  26.40  166.10  2027.0  0.14100   \n",
      "565  0.1752  0.05533   ...     23.690  38.25  155.00  1731.0  0.11660   \n",
      "566  0.1590  0.05648   ...     18.980  34.12  126.70  1124.0  0.11390   \n",
      "567  0.2397  0.07016   ...     25.740  39.42  184.60  1821.0  0.16500   \n",
      "568  0.1587  0.05884   ...      9.456  30.37   59.16   268.6  0.08996   \n",
      "\n",
      "          25       26       27      28       29  \n",
      "0    0.66560  0.71190  0.26540  0.4601  0.11890  \n",
      "1    0.18660  0.24160  0.18600  0.2750  0.08902  \n",
      "2    0.42450  0.45040  0.24300  0.3613  0.08758  \n",
      "3    0.86630  0.68690  0.25750  0.6638  0.17300  \n",
      "4    0.20500  0.40000  0.16250  0.2364  0.07678  \n",
      "5    0.52490  0.53550  0.17410  0.3985  0.12440  \n",
      "6    0.25760  0.37840  0.19320  0.3063  0.08368  \n",
      "7    0.36820  0.26780  0.15560  0.3196  0.11510  \n",
      "8    0.54010  0.53900  0.20600  0.4378  0.10720  \n",
      "9    1.05800  1.10500  0.22100  0.4366  0.20750  \n",
      "10   0.15510  0.14590  0.09975  0.2948  0.08452  \n",
      "11   0.56090  0.39650  0.18100  0.3792  0.10480  \n",
      "12   0.39030  0.36390  0.17670  0.3176  0.10230  \n",
      "13   0.19240  0.23220  0.11190  0.2809  0.06287  \n",
      "14   0.77250  0.69430  0.22080  0.3596  0.14310  \n",
      "15   0.65770  0.70260  0.17120  0.4218  0.13410  \n",
      "16   0.18710  0.29140  0.16090  0.3029  0.08216  \n",
      "17   0.42330  0.47840  0.20730  0.3706  0.11420  \n",
      "18   0.31500  0.53720  0.23880  0.2768  0.07615  \n",
      "19   0.17730  0.23900  0.12880  0.2977  0.07259  \n",
      "20   0.27760  0.18900  0.07283  0.3184  0.08183  \n",
      "21   0.11480  0.08867  0.06227  0.2450  0.07773  \n",
      "22   0.59540  0.63050  0.23930  0.4667  0.09946  \n",
      "23   0.26000  0.31550  0.20090  0.2822  0.07526  \n",
      "24   0.35780  0.46950  0.20950  0.3613  0.09564  \n",
      "25   0.39490  0.38530  0.25500  0.4066  0.10590  \n",
      "26   0.66430  0.55390  0.27010  0.4264  0.12750  \n",
      "27   0.21170  0.34460  0.14900  0.2341  0.07421  \n",
      "28   0.61100  0.63350  0.20240  0.4027  0.09876  \n",
      "29   0.28120  0.24890  0.14560  0.2756  0.07919  \n",
      "..       ...      ...      ...     ...      ...  \n",
      "539  0.30640  0.33930  0.05000  0.2790  0.10660  \n",
      "540  0.21180  0.17970  0.06918  0.2329  0.08134  \n",
      "541  0.42020  0.40400  0.12050  0.3187  0.10230  \n",
      "542  0.13760  0.16110  0.10950  0.2722  0.06956  \n",
      "543  0.13810  0.10620  0.07958  0.2473  0.06443  \n",
      "544  0.20370  0.13770  0.06845  0.2249  0.08492  \n",
      "545  0.15170  0.10490  0.07174  0.2642  0.06953  \n",
      "546  0.08842  0.04384  0.02381  0.2681  0.07399  \n",
      "547  0.22460  0.17830  0.08333  0.2691  0.09479  \n",
      "548  0.09546  0.09350  0.03846  0.2552  0.07920  \n",
      "549  0.16330  0.06194  0.03264  0.3059  0.07626  \n",
      "550  0.07348  0.00000  0.00000  0.2458  0.06592  \n",
      "551  0.17820  0.15640  0.06413  0.3169  0.08032  \n",
      "552  0.10640  0.08653  0.06498  0.2407  0.06484  \n",
      "553  0.08298  0.07993  0.02564  0.2435  0.07393  \n",
      "554  0.16200  0.24390  0.06493  0.2372  0.07242  \n",
      "555  0.17100  0.20000  0.09127  0.2226  0.08283  \n",
      "556  0.12000  0.01005  0.02232  0.2262  0.06742  \n",
      "557  0.07158  0.00000  0.00000  0.2475  0.06969  \n",
      "558  0.31710  0.36620  0.11050  0.2258  0.08004  \n",
      "559  0.25170  0.36300  0.09653  0.2112  0.08732  \n",
      "560  0.22640  0.13260  0.10480  0.2250  0.08321  \n",
      "561  0.05494  0.00000  0.00000  0.1566  0.05905  \n",
      "562  0.79170  1.17000  0.23560  0.4089  0.14090  \n",
      "563  0.41860  0.65990  0.25420  0.2929  0.09873  \n",
      "564  0.21130  0.41070  0.22160  0.2060  0.07115  \n",
      "565  0.19220  0.32150  0.16280  0.2572  0.06637  \n",
      "566  0.30940  0.34030  0.14180  0.2218  0.07820  \n",
      "567  0.86810  0.93870  0.26500  0.4087  0.12400  \n",
      "568  0.06444  0.00000  0.00000  0.2871  0.07039  \n",
      "\n",
      "[569 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# linear scaling for KNN [0 1]\n",
    "# LSVT Dataset\n",
    "# Parkinson's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0      1       2       3        4        5         6         7   \\\n",
      "0    15.460  11.89  102.50   736.9  0.12570  0.15550  0.203200  0.109700   \n",
      "1    12.850  21.37   82.63   514.5  0.07551  0.08316  0.061260  0.018670   \n",
      "2    19.210  18.57  125.50  1152.0  0.10530  0.12670  0.132300  0.089940   \n",
      "3    12.470  17.31   80.45   480.1  0.08928  0.07630  0.036090  0.023690   \n",
      "4    12.460  19.89   80.43   471.3  0.08451  0.10140  0.068300  0.030990   \n",
      "5    10.860  21.48   68.51   360.5  0.07431  0.04227  0.000000  0.000000   \n",
      "6    11.370  18.89   72.17   396.0  0.08713  0.05008  0.023990  0.021730   \n",
      "7    18.810  19.98  120.90  1102.0  0.08923  0.05884  0.080200  0.058430   \n",
      "8    13.490  22.30   86.91   561.0  0.08752  0.07698  0.047510  0.033840   \n",
      "9     9.567  15.91   60.21   279.6  0.08464  0.04087  0.016520  0.016670   \n",
      "10   17.140  16.40  116.00   912.7  0.11860  0.22760  0.222900  0.140100   \n",
      "11   11.060  14.83   70.31   378.2  0.07741  0.04768  0.027120  0.007246   \n",
      "12   14.610  15.69   92.68   664.9  0.07618  0.03515  0.014470  0.018770   \n",
      "13    7.691  25.44   48.34   170.4  0.08668  0.11990  0.092520  0.013640   \n",
      "14   19.070  24.81  128.30  1104.0  0.09081  0.21900  0.210700  0.099610   \n",
      "15   13.690  16.07   87.84   579.1  0.08302  0.06374  0.025560  0.020310   \n",
      "16   19.160  26.60  126.20  1138.0  0.10200  0.14530  0.192100  0.096640   \n",
      "17   19.800  21.56  129.70  1230.0  0.09383  0.13060  0.127200  0.086910   \n",
      "18   11.460  18.16   73.59   403.1  0.08853  0.07694  0.033440  0.015020   \n",
      "19   12.060  18.90   76.66   445.3  0.08386  0.05794  0.007510  0.008488   \n",
      "20   13.150  15.34   85.31   538.9  0.09384  0.08498  0.092930  0.034830   \n",
      "21   13.610  24.69   87.76   572.6  0.09258  0.07862  0.052850  0.030850   \n",
      "22   10.260  16.58   65.85   320.8  0.08877  0.08066  0.043580  0.024380   \n",
      "23    9.333  21.94   59.01   264.0  0.09240  0.05605  0.039960  0.012820   \n",
      "24   11.060  17.12   71.25   366.5  0.11940  0.10710  0.040630  0.042680   \n",
      "25   10.660  15.15   67.49   349.6  0.08792  0.04302  0.000000  0.000000   \n",
      "26   11.840  18.70   77.93   440.6  0.11090  0.15160  0.121800  0.051820   \n",
      "27   10.510  20.19   68.64   334.2  0.11220  0.13030  0.064760  0.030680   \n",
      "28   12.670  17.30   81.25   489.9  0.10280  0.07664  0.031930  0.021070   \n",
      "29   11.080  14.71   70.21   372.7  0.10060  0.05743  0.023630  0.025830   \n",
      "..      ...    ...     ...     ...      ...      ...       ...       ...   \n",
      "351  11.740  14.69   76.31   426.0  0.08099  0.09661  0.067260  0.026390   \n",
      "352  13.050  19.31   82.61   527.2  0.08060  0.03789  0.000692  0.004167   \n",
      "353  10.880  15.62   70.41   358.9  0.10070  0.10690  0.051150  0.015710   \n",
      "354  19.730  19.82  130.70  1206.0  0.10620  0.18490  0.241700  0.097400   \n",
      "355   9.504  12.44   60.34   273.9  0.10240  0.06492  0.029560  0.020760   \n",
      "356  11.540  10.72   73.73   409.1  0.08597  0.05969  0.013670  0.008907   \n",
      "357   9.755  28.20   61.68   290.9  0.07984  0.04626  0.015410  0.010430   \n",
      "358  11.750  20.18   76.10   419.8  0.10890  0.11410  0.068430  0.037380   \n",
      "359  11.330  14.16   71.79   396.6  0.09379  0.03872  0.001487  0.003333   \n",
      "360  12.770  21.41   82.02   507.4  0.08749  0.06601  0.031120  0.028640   \n",
      "361  14.600  23.29   93.97   664.7  0.08682  0.06636  0.083900  0.052710   \n",
      "362  14.990  22.11   97.53   693.7  0.08515  0.10250  0.068590  0.038760   \n",
      "363  17.850  13.23  114.60   992.1  0.07838  0.06217  0.044450  0.041780   \n",
      "364  19.680  21.68  129.90  1194.0  0.09797  0.13390  0.186300  0.110300   \n",
      "365  13.500  12.71   85.69   566.2  0.07376  0.03614  0.002758  0.004419   \n",
      "366  12.190  13.29   79.08   455.8  0.10660  0.09509  0.028550  0.028820   \n",
      "367  14.420  19.77   94.48   642.5  0.09752  0.11410  0.093880  0.058390   \n",
      "368  21.370  15.10  141.30  1386.0  0.10010  0.15150  0.193200  0.125500   \n",
      "369  19.020  24.59  122.00  1076.0  0.09029  0.12060  0.146800  0.082710   \n",
      "370  13.000  25.13   82.61   520.2  0.08369  0.05073  0.012060  0.017620   \n",
      "371  16.030  15.51  105.80   793.2  0.09491  0.13710  0.120400  0.070410   \n",
      "372  14.190  23.81   92.87   610.7  0.09463  0.13060  0.111500  0.064620   \n",
      "373  13.140  20.74   85.98   536.9  0.08675  0.10890  0.108500  0.035100   \n",
      "374  18.660  17.12  121.40  1077.0  0.10540  0.11000  0.145700  0.086650   \n",
      "375  13.080  15.71   85.63   520.0  0.10750  0.12700  0.045680  0.031100   \n",
      "376   8.888  14.64   58.79   244.0  0.09783  0.15310  0.086060  0.028720   \n",
      "377  11.640  18.33   75.17   412.5  0.11420  0.10170  0.070700  0.034850   \n",
      "378  14.290  16.82   90.30   632.6  0.06429  0.02675  0.007250  0.006250   \n",
      "379  13.980  19.62   91.12   599.5  0.10600  0.11330  0.112600  0.064630   \n",
      "380  12.180  20.52   77.22   458.7  0.08013  0.04038  0.023830  0.017700   \n",
      "\n",
      "         8        9    ...         20     21      22      23       24  \\\n",
      "0    0.1966  0.07069   ...     18.790  17.04  125.00  1102.0  0.15310   \n",
      "1    0.1580  0.06114   ...     14.400  27.01   91.63   645.8  0.09402   \n",
      "2    0.1917  0.05961   ...     26.140  28.14  170.10  2145.0  0.16240   \n",
      "3    0.1526  0.06046   ...     14.060  24.34   92.82   607.3  0.12760   \n",
      "4    0.1781  0.06249   ...     13.460  23.07   88.13   551.3  0.10500   \n",
      "5    0.1661  0.05948   ...     11.660  24.77   74.08   412.3  0.10010   \n",
      "6    0.2013  0.05955   ...     12.360  26.14   79.29   459.3  0.11180   \n",
      "7    0.1550  0.04996   ...     19.960  24.30  129.00  1236.0  0.12430   \n",
      "8    0.1809  0.05718   ...     15.150  31.82   99.00   698.8  0.11620   \n",
      "9    0.1551  0.06403   ...     10.510  19.16   65.74   335.9  0.15040   \n",
      "10   0.3040  0.07413   ...     22.250  21.40  152.40  1461.0  0.15450   \n",
      "11   0.1535  0.06214   ...     12.680  20.35   80.79   496.7  0.11200   \n",
      "12   0.1632  0.05255   ...     16.460  21.75  103.70   840.8  0.10110   \n",
      "13   0.2037  0.07751   ...      8.678  31.89   54.49   223.6  0.15960   \n",
      "14   0.2310  0.06343   ...     24.090  33.17  177.40  1651.0  0.12470   \n",
      "15   0.1872  0.05669   ...     14.840  20.21   99.16   670.6  0.11050   \n",
      "16   0.1902  0.06220   ...     23.720  35.90  159.80  1724.0  0.17820   \n",
      "17   0.2094  0.05581   ...     25.730  28.64  170.30  2009.0  0.13530   \n",
      "18   0.1411  0.06243   ...     12.680  21.61   82.69   489.8  0.11440   \n",
      "19   0.1555  0.06048   ...     13.640  27.06   86.54   562.6  0.12890   \n",
      "20   0.1822  0.06207   ...     14.770  20.50   97.67   677.3  0.14780   \n",
      "21   0.1761  0.06130   ...     16.890  35.64  113.20   848.7  0.14710   \n",
      "22   0.1669  0.06714   ...     10.830  22.04   71.08   357.4  0.14610   \n",
      "23   0.1692  0.06576   ...      9.845  25.05   62.86   295.8  0.11030   \n",
      "24   0.1954  0.07976   ...     11.690  20.74   76.08   411.1  0.16620   \n",
      "25   0.1928  0.05975   ...     11.540  19.20   73.20   408.3  0.10760   \n",
      "26   0.2301  0.07799   ...     16.820  28.12  119.40   888.7  0.16370   \n",
      "27   0.1922  0.07782   ...     11.160  22.75   72.62   374.4  0.13000   \n",
      "28   0.1707  0.05984   ...     13.710  21.10   88.70   574.4  0.13840   \n",
      "29   0.1566  0.06669   ...     11.350  16.82   72.01   396.5  0.12160   \n",
      "..      ...      ...   ...        ...    ...     ...     ...      ...   \n",
      "351  0.1499  0.06758   ...     12.450  17.60   81.25   473.8  0.10730   \n",
      "352  0.1819  0.05501   ...     14.230  22.25   90.24   624.1  0.10210   \n",
      "353  0.1861  0.06837   ...     11.940  19.35   80.78   433.1  0.13320   \n",
      "354  0.1733  0.06697   ...     25.280  25.59  159.80  1933.0  0.17100   \n",
      "355  0.1815  0.06905   ...     10.230  15.66   65.13   314.9  0.13240   \n",
      "356  0.1833  0.06100   ...     12.340  12.87   81.23   467.8  0.10920   \n",
      "357  0.1621  0.05952   ...     10.670  36.92   68.03   349.9  0.11100   \n",
      "358  0.1993  0.06453   ...     13.320  26.21   88.91   543.9  0.13580   \n",
      "359  0.1954  0.05821   ...     12.200  18.99   77.37   458.0  0.12590   \n",
      "360  0.1694  0.06287   ...     13.750  23.50   89.04   579.5  0.09388   \n",
      "361  0.1627  0.05416   ...     15.790  31.71  102.20   758.2  0.13120   \n",
      "362  0.1944  0.05913   ...     16.760  31.55  110.20   867.1  0.10770   \n",
      "363  0.1220  0.05243   ...     19.820  18.42  127.10  1210.0  0.09862   \n",
      "364  0.2082  0.05715   ...     22.750  34.66  157.60  1540.0  0.12180   \n",
      "365  0.1365  0.05335   ...     14.970  16.94   95.48   698.7  0.09023   \n",
      "366  0.1880  0.06471   ...     13.340  17.81   91.38   545.2  0.14270   \n",
      "367  0.1879  0.06390   ...     16.330  30.86  109.50   826.4  0.14310   \n",
      "368  0.1973  0.06183   ...     22.690  21.84  152.10  1535.0  0.11920   \n",
      "369  0.1953  0.05629   ...     24.560  30.41  152.90  1623.0  0.12490   \n",
      "370  0.1667  0.05449   ...     14.340  31.88   91.06   628.5  0.12180   \n",
      "371  0.1782  0.05976   ...     18.760  21.98  124.30  1070.0  0.14350   \n",
      "372  0.2235  0.06433   ...     16.860  34.85  115.00   811.3  0.15590   \n",
      "373  0.1562  0.06020   ...     14.800  25.46  100.90   689.1  0.13510   \n",
      "374  0.1966  0.06213   ...     22.250  24.90  145.40  1549.0  0.15030   \n",
      "375  0.1967  0.06811   ...     14.500  20.49   96.09   630.5  0.13120   \n",
      "376  0.1902  0.08980   ...      9.733  15.67   62.56   284.4  0.12070   \n",
      "377  0.1801  0.06520   ...     13.140  29.26   85.51   521.7  0.16880   \n",
      "378  0.1508  0.05376   ...     14.910  20.65   94.44   684.6  0.08567   \n",
      "379  0.1669  0.06544   ...     17.040  30.80  113.90   869.3  0.16130   \n",
      "380  0.1739  0.05677   ...     13.340  32.84   84.58   547.8  0.11230   \n",
      "\n",
      "          25        26       27      28       29  \n",
      "0    0.35830  0.583000  0.18270  0.3216  0.10100  \n",
      "1    0.19360  0.183800  0.05601  0.2488  0.08151  \n",
      "2    0.35110  0.387900  0.20910  0.3537  0.08294  \n",
      "3    0.25060  0.202800  0.10530  0.3035  0.07661  \n",
      "4    0.21580  0.190400  0.07625  0.2685  0.07764  \n",
      "5    0.07348  0.000000  0.00000  0.2458  0.06592  \n",
      "6    0.09708  0.075290  0.06203  0.3267  0.06994  \n",
      "7    0.11600  0.221000  0.12940  0.2567  0.05737  \n",
      "8    0.17110  0.228200  0.12820  0.2871  0.06917  \n",
      "9    0.09515  0.071610  0.07222  0.2757  0.08178  \n",
      "10   0.39490  0.385300  0.25500  0.4066  0.10590  \n",
      "11   0.18790  0.207900  0.05556  0.2590  0.09158  \n",
      "12   0.07087  0.047460  0.05813  0.2530  0.05695  \n",
      "13   0.30640  0.339300  0.05000  0.2790  0.10660  \n",
      "14   0.74440  0.724200  0.24930  0.4670  0.10380  \n",
      "15   0.20960  0.134600  0.06987  0.3323  0.07701  \n",
      "16   0.38410  0.575400  0.18720  0.3258  0.09720  \n",
      "17   0.32350  0.361700  0.18200  0.3070  0.08255  \n",
      "18   0.17890  0.122600  0.05509  0.2208  0.07638  \n",
      "19   0.13520  0.045060  0.05093  0.2880  0.08083  \n",
      "20   0.22560  0.300900  0.09722  0.3849  0.08633  \n",
      "21   0.28840  0.379600  0.13290  0.3470  0.07900  \n",
      "22   0.22460  0.178300  0.08333  0.2691  0.09479  \n",
      "23   0.08298  0.079930  0.02564  0.2435  0.07393  \n",
      "24   0.20310  0.125600  0.09514  0.2780  0.11680  \n",
      "25   0.06791  0.000000  0.00000  0.2710  0.06164  \n",
      "26   0.57750  0.695600  0.15460  0.4761  0.14020  \n",
      "27   0.20490  0.129500  0.06136  0.2383  0.09026  \n",
      "28   0.12120  0.102000  0.05602  0.2688  0.06888  \n",
      "29   0.08240  0.039380  0.04306  0.1902  0.07313  \n",
      "..       ...       ...      ...     ...      ...  \n",
      "351  0.27930  0.269000  0.10560  0.2604  0.09879  \n",
      "352  0.06191  0.001845  0.01111  0.2439  0.06289  \n",
      "353  0.38980  0.336500  0.07966  0.2581  0.10800  \n",
      "354  0.59550  0.848900  0.25070  0.2749  0.12970  \n",
      "355  0.11480  0.088670  0.06227  0.2450  0.07773  \n",
      "356  0.16260  0.083240  0.04715  0.3390  0.07434  \n",
      "357  0.11090  0.071900  0.04866  0.2321  0.07211  \n",
      "358  0.18920  0.195600  0.07909  0.3168  0.07987  \n",
      "359  0.07348  0.004955  0.01111  0.2758  0.06386  \n",
      "360  0.08978  0.051860  0.04773  0.2179  0.06871  \n",
      "361  0.15810  0.267500  0.13590  0.2477  0.06836  \n",
      "362  0.33450  0.311400  0.13080  0.3163  0.09251  \n",
      "363  0.09976  0.104800  0.08341  0.1783  0.05871  \n",
      "364  0.34580  0.473400  0.22550  0.4045  0.07918  \n",
      "365  0.05836  0.013790  0.02210  0.2267  0.06192  \n",
      "366  0.25850  0.099150  0.08187  0.3469  0.09241  \n",
      "367  0.30260  0.319400  0.15650  0.2718  0.09353  \n",
      "368  0.28400  0.402400  0.19660  0.2730  0.08666  \n",
      "369  0.32060  0.575500  0.19560  0.3956  0.09288  \n",
      "370  0.10930  0.044620  0.05921  0.2306  0.06291  \n",
      "371  0.44780  0.495600  0.19810  0.3019  0.09124  \n",
      "372  0.40590  0.374400  0.17720  0.4724  0.10260  \n",
      "373  0.35490  0.450400  0.11810  0.2563  0.08174  \n",
      "374  0.22910  0.327200  0.16740  0.2894  0.08456  \n",
      "375  0.27760  0.189000  0.07283  0.3184  0.08183  \n",
      "376  0.24360  0.143400  0.04786  0.2254  0.10840  \n",
      "377  0.26600  0.287300  0.12180  0.2806  0.09097  \n",
      "378  0.05036  0.038660  0.03333  0.2458  0.06120  \n",
      "379  0.35680  0.406900  0.18270  0.3179  0.10550  \n",
      "380  0.08862  0.114500  0.07431  0.2694  0.06878  \n",
      "\n",
      "[381 rows x 30 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
